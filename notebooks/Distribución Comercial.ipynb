{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%cd C:\\Users\\mgrinberg\\Desktop\\disc c\\SDPC\\SDPC\\SDPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from variables import *\n",
    "from SDPC_utils import *\n",
    "\n",
    "import ctypes\n",
    "import pickle as pkl\n",
    "import pandas as dd\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "from collections import OrderedDict\n",
    "from time import time, strftime\n",
    "from os import getcwd\n",
    "import re\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from scipy.sparse import csr_matrix, save_npz, load_npz, diags\n",
    "from scipy.sparse.linalg import lsqr\n",
    "from scipy.linalg import orth\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_data(query=None, to_sql = False):\n",
    "    \"\"\"Toma los datos del .lst indicado o hace query a SQL server. \n",
    "    Genera Maestro e Historico.\"\"\"\n",
    "    \n",
    "    t0 = time()\n",
    "    if type(query) == type(None):\n",
    "        lsts = [p for p in os.listdir(TMP_PATH) if p.endswith('.lst')]\n",
    "        print(f\"{len(lsts)} '.lst's encontrados.\")\n",
    "        df = pd.DataFrame()\n",
    "        for p in lsts:\n",
    "            df_ = read_lst(os.path.join(TMP_PATH, p), lst_cols)\n",
    "            df_ = preprocesamiento(df_)\n",
    "            df_['Base'] = p.split('.')[0]\n",
    "            df = pd.concat([df, df_])       \n",
    "        \n",
    "        df.groupby([cl_col, s_col, p_col]) \\\n",
    "            .agg({neto_col: 'mean'}) \\\n",
    "            .sort_index()[neto_col].reset_index().to_csv(TMP_PATH+'Historico.csv', sep=';', index = False)\n",
    "                \n",
    "        #Exportar maestr\n",
    "        wb = xw.Book(MASTER_PATH)\n",
    "        wb.sheets['Maestro'].range('A2', 'T200000').clear()\n",
    "        wb.sheets['Maestro'].range('A6').value = ''\n",
    "        wb.sheets['Maestro'].range('A1').options(pd.DataFrame, index=False).value = df.groupby([cl_col, s_col]).agg({c_col:'last', nom_cli_col: 'last', \n",
    "                                                                                                                   cir_col:'last'}).reset_index()\n",
    "        \n",
    "    else:\n",
    "        engine = sqlalchemy.create_engine(f\"mssql+pyodbc://{UID}:{PWD}@{SERVER}/{DATABASE}?driver=SQL+Server\")\n",
    "        df = pd.read_sql_query(query, engine, index_col='index').to_csv(TMP_PATH+'Historico.csv', sep=';', index = False)\n",
    "    \n",
    "    if to_sql:\n",
    "        to_sql(df)\n",
    "   \n",
    "    ctypes.windll.user32.MessageBoxW(0, f\"Datos cargados. {time() - t0:.0f} segundos.\",  \"Terminado\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocesamiento(df):\n",
    "    from variables import c_col, cl_col, p_col, z_col, s_col, fl_col, fle_col, cir_col, q_col, dev_col, neto_col\n",
    "    \n",
    "    # Tranformo a numerico\n",
    "    df[[q_col, dev_col]] = df[[q_col, dev_col]].apply(lambda x: pd.to_numeric(x.astype(str).str.replace(',','.'), errors='coerce'))\n",
    "    df[[c_col, cl_col, p_col, z_col, s_col, fl_col, fle_col, cir_col]] = df[[c_col, cl_col, p_col, z_col, s_col, fl_col, fle_col, cir_col]].apply(lambda x: pd.to_numeric(x, errors= 'coerce', downcast='integer'))\n",
    "    \n",
    "    # Saco nulos y el ultimo que era '\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'\n",
    "    df = df.dropna(how='all')\n",
    "    #df = df[:-1]\n",
    "    \n",
    "    df = df.rename({'Regi¢n':'Region'}, axis=1)\n",
    "\n",
    "    # Calculo venta bruta \n",
    "    df[neto_col] = (df[q_col] - df[dev_col]).astype('float64')\n",
    "\n",
    "    # Se borran ventas netas negativas\n",
    "    df = df[df[neto_col] > 0]\n",
    "    \n",
    "    df = df.groupby([cl_col, s_col, p_col])\\\n",
    "        .agg({c_col:'last', z_col:'last', nom_cli_col: 'last', cir_col:'last', fl_col:'last', neto_col:'sum'}) \\\n",
    "        .reset_index()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribuir_como(df):\n",
    "    \"\"\"Copia distribución entre productos.\n",
    "    df := Dataframe;\"\"\"\n",
    "    wb = xw.Book(MASTER_PATH)   \n",
    "    # Se leen modificaciones\n",
    "    mod_cl = get_table(wb, 'ETL', [cl_col+' | '+s_col, p_col, 'Dist. Como'], cast_num=False)\n",
    "    copias = [df]\n",
    "    for idx, row in mod_cl.iterrows():\n",
    "        nue, orig = row.dropna()\n",
    "        if re.search('\\d[\\s,\\-|]+\\d', str(orig)):\n",
    "            c, s = [int(n) for n in re.split('\\D', orig) if n.isdigit()]\n",
    "            n_c, n_s = [int(n) for n in re.split('\\D', nue) if n.isdigit()]\n",
    "            _ = df.loc[(df[cl_col] == c) & (df[s_col] == s), :].copy()\n",
    "            _.loc[:, [cl_col, s_col]] = [n_c, n_s]\n",
    "        else:\n",
    "            _ = df[df[p_col] == float(orig)].copy()\n",
    "            _[p_col] = float(nue)\n",
    "        copias.append(_)\n",
    "\n",
    "    return pd.concat(copias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actualizar_base():\n",
    "    \"\"\"Lee Historico y devuelve punto de partida (warm start) para optimización. \n",
    "    Si se indica ignorar_cl_m, se ignoran los clientes en el maestro sin distribución previa. \n",
    "    Si no, se eleva un error para indicar el ingreso de 'Dist. Como'\"\"\"\n",
    "    t0 = time()\n",
    "    Q0 = pd.read_csv(TMP_PATH + 'Historico.csv', sep=';')\n",
    "\n",
    "    Q0 = distribuir_como(Q0)\n",
    "    \n",
    "    if Q0[Q0.duplicated(subset=[cl_col, s_col, p_col])].shape[0] > 0 : \n",
    "        print('Advertencia, hay en \"Dist. Como\" un producto a distribuir que ya existía en la distribución. \\n', Q0[Q0.duplicated(subset=[cl_col, s_col, p_col])][p_col].unique())\n",
    "    \n",
    "    # eliminar repetidos?\n",
    "    Q0 = Q0.groupby([cl_col, s_col, p_col]) \\\n",
    "            .agg({neto_col: 'sum'}) \\\n",
    "            .reset_index()\n",
    "\n",
    "    # Quitar productos que no estan en presup\n",
    "    restr, errs, PRESUP = get_restricciones()\n",
    "    Q0 = Q0[Q0[p_col].isin(PRESUP.index)]\n",
    "    # Normalizacion sobre total prod\n",
    "    Q0[neto_col+'_w'] = Q0.groupby(p_col)[neto_col].apply(lambda x: x / x.sum())\n",
    "    # Participacion pasada x PRESUP da el warm start\n",
    "    Q0[neto_col+'_w'] = Q0.groupby(p_col)[neto_col+'_w'].apply(lambda x: x * PRESUP[x.name])\n",
    "\n",
    "\n",
    "    wb = xw.Book(MASTER_PATH)\n",
    "    m = get_table(wb, 'Maestro', [cl_col, s_col, c_col, z_col, nom_cli_col, cir_col], cast_num=False)\n",
    "\n",
    "    tabla_cl = get_table(wb, 'Tabla Clientes', [c_col, ge_col, cl_col], cast_num=False)\n",
    "    tabla_pr = get_table(wb, 'Tabla Productos', [p_col, 'Nombre '+ p_col, fl_col, gr_col], cast_num=False)\n",
    "\n",
    "    d = defaultdict(LabelEncoder)\n",
    "    tabla_cl[[ge_col, c_col]] = tabla_cl[[ge_col, c_col]].apply(lambda x: d[x.name].fit_transform(x))\n",
    "    tabla_pr[[fl_col]] = tabla_pr[[fl_col]].apply(lambda x: d[x.name].fit_transform(x))\n",
    "    tabla_pr[p_col] = pd.to_numeric(tabla_pr[p_col], downcast='integer')\n",
    "\n",
    "    Q0[p_col] = pd.to_numeric(Q0[p_col])\n",
    "    \n",
    "    d = {k:list(v.classes_) for k,v in d.items()}\n",
    "    d['Canal'].append('Default')\n",
    "    default = len(d['Canal'])\n",
    "    # output codigos\n",
    "    _ = pd.DataFrame.from_dict(d, orient='index').T\n",
    "    _.index.name = 'Codigo'\n",
    "    wb.sheets['Codigos'].range('A1').options(pd.DataFrame, index=True).value = _\n",
    "    del _\n",
    "\n",
    "    # data cl a maestro\n",
    "    m = pd.merge(tabla_cl, m, how='right', on=[cl_col], suffixes=('','_0'))\n",
    "    m = m.loc[:, ~m.columns.str.endswith('_0')]\n",
    "    m = m.fillna(default)\n",
    "\n",
    "    #Maestro. Se guardan los ultimos\n",
    "    wb.sheets['Maestro'].range('A2', 'T200000').clear()\n",
    "    wb.sheets['Maestro'].range('A1').options(pd.DataFrame, index=False).value = m[[c_col, s_col, cl_col, nom_cli_col, cir_col, ge_col]]\n",
    "        \n",
    "    Q0 = pd.merge(tabla_pr.loc[:,[p_col, fl_col]], Q0, how='right', on=[p_col], suffixes=('','_0'))\n",
    "    Q0 = Q0.loc[:, ~Q0.columns.str.endswith('_0')]\n",
    "\n",
    "    # data cl maestro a q0\n",
    "    Q0 = pd.merge(Q0, m, how='right', on=[cl_col, s_col], suffixes=('_0',''))\n",
    "    Q0 = Q0.loc[:, ~Q0.columns.str.endswith('_0')]\n",
    "\n",
    "    if PRESUP[~PRESUP.index.isin(tabla_pr[p_col])].shape[0] > 0: \n",
    "        raise Exception('Falta información en la tabla para los siguientes productos', PRESUP[~PRESUP.index.isin(tabla_pr[p_col])].values)\n",
    "    if not Q0[Q0.isnull().any(axis=1)].shape[0] == 0: \n",
    "        print(\"Falta la distribución de productos para Cliente, Sucursal\", Q0[Q0.isnull().any(axis=1)][[cl_col, s_col]].astype(int).values.tolist())\n",
    "        Q0 = Q0.dropna(axis=0)\n",
    "    if not Q0[cl_col].isin(m[cl_col]).all(): raise Exception(\"Se encontraron sin distribución de productos los clientes, sucursales:\", Q0[Q0.isnull().any(axis=1)][cl_col].astype(int).values.tolist())\n",
    "    if not Q0[p_col].isin(PRESUP.index).all(): raise Exception( \"Error. Productos fuera de presupuesto.\", Q0[~Q0[p_col].isin(PRESUP.index)].astype(int).values.tolist())\n",
    "\n",
    "    assert Q0[Q0.isnull().any(axis=1)].shape[0] == 0\n",
    "\n",
    "    Q0.drop(nom_cli_col, axis=1).astype('float64').to_csv(TMP_PATH + 'Q1.csv', sep = ';', index=False)\n",
    "    ctypes.windll.user32.MessageBoxW(0, f\"Base modificada. {time() - t0:.0f} segundos.\",  \"Terminado\", 1)\n",
    "    return Q0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_restricciones():\n",
    "    \"\"\"Toma tabla de restricciones.\"\"\"\n",
    "    \n",
    "    wb = xw.Book(MASTER_PATH)\n",
    "    restr = get_table(wb, 'Restricciones', 'Zona, C.MHSA, Canal, Grupo Economico, Cliente, Suc., Flia., Prod., Simb., Cantidad, Porcentaje del Total, Porcentaje Relativo'.split(', '), cast_num=False)\n",
    "    restr['Simb.'].replace({'<=':1, '.=':0, np.nan:0}, inplace=True)\n",
    "\n",
    "    # Extrae las filas del presupuesto (filas SOLO con producto - cantidad)\n",
    "    restr = restr.apply(lambda x: pd.to_numeric(x, errors= 'coerce', downcast='integer'))\n",
    "    PRESUP = restr[restr.loc[:, restr.columns[~restr.columns.isin(['Cantidad', p_col, 'Simb.'])]]\n",
    "                   .isnull().all(axis = 1)].set_index(p_col)['Cantidad'].sort_index()\n",
    "    PRESUP = PRESUP[(PRESUP.index.notna()) & (PRESUP > 0)]\n",
    "\n",
    "    valid_left = restr.iloc[:, :8].notna().any(axis=1)\n",
    "    valid_right = restr.iloc[:, [9, 10, 11]].notna().any(axis=1)\n",
    "    errs = restr[~(valid_left & valid_right)].index\n",
    "    if len(errs) > 0: print(f'Errores en restricciones con indices {errs.values + 2}')\n",
    "    restr = restr[valid_left&valid_right]\n",
    "    \n",
    "    return restr, errs.to_series(), PRESUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_vars():\n",
    "    \"\"\"Toma Q1.csv y las restricciones y prepara matrices para optimización.\"\"\"\n",
    "    Q = pd.read_csv(TMP_PATH + 'Q1.csv', sep=';')\n",
    "    \n",
    "    x = Q[neto_col+'_w'].values\n",
    "    np.savetxt(TMP_PATH + r'\\x.gz', x)\n",
    "    #del x\n",
    "    \n",
    "    #Q = Q.iloc[:,:-2]\n",
    "    pr_fl = Q.groupby(p_col)[fl_col].first()\n",
    "    \n",
    "    restr, errs, PRESUP = get_restricciones()\n",
    "    \n",
    "    A = []\n",
    "    b = []\n",
    "    \n",
    "    for i, row in restr.iterrows():\n",
    "        cols = row.iloc[:-4].dropna()\n",
    "        mask = np.logical_and.reduce([(Q[c] == v) for c,v in cols.items()])\n",
    "        A.append(mask)\n",
    "\n",
    "        row = row.dropna()\n",
    "\n",
    "        if 'Cantidad' in row.index:\n",
    "            if ((fl_col in row.index) | (p_col in row.index)):\n",
    "                b.append(row['Cantidad'])\n",
    "            else:\n",
    "                b.append(PRESUP.sum())\n",
    "        elif 'Porcentaje Relativo' in row.index:\n",
    "            uni = (row['Porcentaje Relativo']/100) * (Q[neto_col+'_w'].values @ mask)\n",
    "            b.append(uni)\n",
    "        elif 'Porcentaje del Total' in row.index:\n",
    "            if (fl_col in row.index):\n",
    "                uni = (row['Porcentaje del Total']/100) * PRESUP.loc[pr_fl[pr_fl == row[fl_col]].index.values].sum()\n",
    "            elif p_col in row.index:\n",
    "                uni = (row['Porcentaje del Total']/100) * PRESUP[pr_fl[pr_fl.index == row[p_col]].index.values].sum()\n",
    "            else:\n",
    "                uni = (row['Porcentaje del Total']/100) * PRESUP.sum()\n",
    "            b.append(uni)\n",
    "        else:\n",
    "            raise Exception(\"##\")\n",
    "\n",
    "    idx_ineqs = restr[restr.iloc[:,-3] == 1].index.values.astype('int32')\n",
    "    A = csr_matrix(np.vstack(A).astype('bool'))\n",
    "    b = np.array(b).astype('int64')\n",
    "    save_npz(TMP_PATH + r'\\A.npz', A)\n",
    "    np.savetxt(TMP_PATH + r'\\b.gz', b)\n",
    "    np.savetxt(TMP_PATH + r'\\idx_ineqs.gz', idx_ineqs)\n",
    "    \n",
    "    return A, x, b, idx_ineqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_constraints(margen=10, q = None):\n",
    "    print('Ingresando resultados en Restricciones.')\n",
    "    A_, q_, b_ = [TMP_PATH + p for p in ['A.npz', 'x.gz', 'b.gz']]\n",
    "    A = load_npz(A_)\n",
    "    if type(q) == type(None):\n",
    "        q = np.loadtxt(q_)\n",
    "    b = np.loadtxt(b_)\n",
    "\n",
    "    wb = xw.Book(MASTER_PATH)\n",
    "    restr = get_table(wb, 'Restricciones', 'Zona, C.MHSA, Canal, Grupo Economico, Cliente, Suc., Flia., Prod., Simb., Cantidad, Porcentaje del Total, Porcentaje Relativo'.split(', '), cast_num = False)\n",
    "    restr, inval, PRESUP = get_restricciones()    \n",
    "    \n",
    "    res = []\n",
    "    margen = 100\n",
    "    for i in range(A.shape[0]):\n",
    "        active = q[A[i].toarray().ravel()]\n",
    "        # total para restriccion\n",
    "        s = active.sum().astype(int)\n",
    "        # satisfecho bool para restriccion\n",
    "        r = s <= b[i] + margen \n",
    "        resto = s - b[i] \n",
    "        res.append((str(r), str(b[i]), str(s), str(round(resto, 0)), str(round((s/b[i]) * 100, 1))))\n",
    "\n",
    "    for n in inval:\n",
    "        res.insert(n, ('NA','NA','NA', 'NA', 'NA'))  \n",
    "    \n",
    "    wb = xw.Book(MASTER_PATH)\n",
    "    wb.sheets['Restricciones'].range('P2').value = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validar(Q = None):\n",
    "    t0 = time()\n",
    "    print('Volcando resultado en Análisis.')\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    wb = xw.Book(MASTER_PATH)\n",
    "    filtro = get_table(wb, 'Filtro', [z_col, c_col, cl_col, s_col, cir_col, fl_col, p_col])\n",
    "    filtro.dropna(how='all', inplace=True)\n",
    "    if Q is None:\n",
    "        Q = pd.read_csv(TMP_PATH+'Q1.csv', sep=';')\n",
    "\n",
    "    data, fig = check_sol(Q=Q, show=True, th1=0.7, th2=0.3)\n",
    "    check_constraints(q = Q[neto_col+'_1'].values)    \n",
    "    \n",
    "    if filtro.shape[0] == 0:\n",
    "        mask = np.ones(Q.shape[0]).astype(bool)\n",
    "    else:\n",
    "        masks = []\n",
    "        for i, row in filtro.iterrows():\n",
    "            row = row.dropna()\n",
    "            mask_ = np.logical_and.reduce([(Q[c] == v) for c, v in row.items()])\n",
    "            masks.append(mask_)\n",
    "        mask = np.logical_or.reduce(masks)\n",
    "    \n",
    "    Q = Q.loc[mask, :]\n",
    "\n",
    "    wb.sheets['Visualización'].pictures.add(fig, name='Dist. de diferencias', update=True)\n",
    "    wb.sheets['Visualización'].range('C4').options(transpose=False).value = {k:v for k,v in data.items() if k not in ['Negativos']}\n",
    "    \n",
    "    wb.sheets['Análisis'].range('A2', 'T100000').clear()\n",
    "    wb.sheets['Análisis'].range('A1').options(pd.DataFrame).value = Q.groupby([cl_col, s_col]).agg({neto_col:'sum', neto_col+'_w':'sum',neto_col+'_1':'sum'}).round(3)\n",
    "    wb.sheets['Análisis'].range('H1').options(pd.DataFrame).value = Q.groupby([c_col, fl_col]).agg({neto_col:'sum', neto_col+'_w':'sum',neto_col+'_1':'sum'}).round(3)\n",
    "    wb.sheets['Análisis'].range('O1').options(pd.DataFrame).value = Q.groupby([cir_col, fl_col]).agg({neto_col:'sum', neto_col+'_w':'sum',neto_col+'_1':'sum'}).round(3)\n",
    "    \n",
    "    wb.sheets['Análisis'].range('F2').options(transpose=True).value = [f\"=ROUND((E{c}-D{c})/D{c}*100, 2)\" for c in range(2, Q.groupby([cl_col, s_col]).count().shape[0]+2)]\n",
    "    wb.sheets['Análisis'].range('M2').options(transpose=True).value = [f\"=ROUND((L{c}-K{c})/K{c}*100, 2)\" for c in range(2, Q.groupby([c_col, fl_col]).count().shape[0]+2)]\n",
    "    wb.sheets['Análisis'].range('T2').options(transpose=True).value = [f\"=ROUND((S{c}-R{c})/R{c}*100, 2)\" for c in range(2, Q.groupby([cir_col, fl_col]).count().shape[0]+2)]\n",
    "    \n",
    "    ctypes.windll.user32.MessageBoxW(0, f\"Análisis terminado. {time() - t0:.0f} segundos.\",  \"Terminado\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_nras(A, q, b, idx_ineqs, precision=10, verbose=False):\n",
    "    c = 0\n",
    "    d_ = np.inf\n",
    "    while True:\n",
    "        p = (b / (A @ q))\n",
    "        idx_ineqs_ok = np.where(p[idx_ineqs] > 1 + 1e-10)\n",
    "        p[idx_ineqs_ok] = 1\n",
    "        A_= A.multiply(p[:, np.newaxis])\n",
    "        P = np.squeeze(np.array(np.true_divide(A_.sum(0), (A_!=0).sum(0))))\n",
    "        q = q * P\n",
    "        d = np.linalg.norm((b - (A @ q))[[idx for idx in range(A.shape[0]) if idx not in idx_ineqs_ok]])\n",
    "        if verbose: print(d, end='\\t')\n",
    "        if d >= d_:\n",
    "            c += 1\n",
    "        d_ = d\n",
    "        if (c == 10) | (d_ < precision):\n",
    "            break\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_ultra(A, q0, b, idx_ineqs, th_max=1, th_min=0.3, max_iters=10, min_coef=2, max_coef=5,  margin=10, pt=1, pc=2, max_tries=3, shuffle=True):\n",
    "    \"\"\"Resuelve resolviendo mediante norma 2 y luego iterando hacia norma inf\"\"\"\n",
    "    #indices de igualdades\n",
    "    eqs = [n for n in range(b.shape[0]) if n not in idx_ineqs.astype(int)]\n",
    "    #resultados actuales\n",
    "    b_ = A @ q0\n",
    "    # Se les asigna a las inecuaciones incumplidas el valor maximo permitido\n",
    "    idx_ineqs_ok = np.intersect1d(np.where((b - b_) > 0), idx_ineqs).astype(int)\n",
    "    b[idx_ineqs_ok] = b_[idx_ineqs_ok]\n",
    "    \n",
    "    #least squares\n",
    "    sol, *_ = lsqr(A, b)\n",
    "    #de var a subesp\n",
    "    o = q0 - sol\n",
    "    W = diags(q0).tocsr()\n",
    "    \n",
    "    thresh = np.linspace(th_min, th_max, max_iters)**pt\n",
    "    coefs = np.linspace(min_coef**(1/2), max_coef**(1/2), max_iters)**pc\n",
    "    res, fig = check_sol(A, q0, b, show=False)\n",
    "    t = 0\n",
    "    i = 0\n",
    "    while True:\n",
    "        i += 1\n",
    "        if i == max_tries+1:\n",
    "            break\n",
    "        print(f\"Thresh {thresh[-i]:.2f} Coef {coefs[-i]:.2f} { {k:round(v, 2) for k,v in res.items()} } \")\n",
    "        ort = orth((A @ W).T.todense())\n",
    "        base = W @ ort\n",
    "        x = o - base @ (base.T @ (W.power(-2) @ o))\n",
    "        q_ = x + sol\n",
    "        res_, fig_ = check_sol(A, q_, b, i=i, t=t, show=False, th1=th_max, th2=th_min)\n",
    "        if not ((res_['Max'] < res['Max']) or (res_['Min'] > res['Min']) or (res_['Norma Aq-b'] < res['Norma Aq-b'] - margin)):\n",
    "            if (t == 1) and shuffle:\n",
    "                np.random.shuffle(thresh)\n",
    "                np.random.shuffle(coefs)\n",
    "            elif t == max_tries:\n",
    "                print('Max tries reached.')\n",
    "                break\n",
    "            else:\n",
    "                t += 1\n",
    "                continue\n",
    "        q = q_\n",
    "        res = res_    \n",
    "        idx = np.argwhere(np.abs(W.power(-1) @ (q_ - q0)) > thresh[-i]).flatten().astype(int)\n",
    "        if idx.shape[0] == 0:\n",
    "            continue\n",
    "        W[idx, idx] = W[idx, idx] * (1 / coefs[-i]) \n",
    "    return q, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sol(A=None, q = None, b=None, Q = None, i = 0, t = 0, show=True, th1=0.60, th2=0.3, xlim=(-1, 1), ylim=None):\n",
    "    if Q is None:\n",
    "        Q = pd.read_csv(TMP_PATH + 'Q1.csv', sep=';')\n",
    "    if q is None:\n",
    "        q = Q[neto_col+'_1']\n",
    "    if A is None:\n",
    "        A,_,b,idx_ineqs = prepare_vars()\n",
    "        del _\n",
    "    data = (np.linalg.norm(Q['Dif'], ord=2), np.linalg.norm(A @ q - b), Q[Q[neto_col+'_1'] <= 0].shape[0], *Q[neto_col+'_1'].summary().values[1:])\n",
    "    names = f'Norma q-q0, Norma Aq-b, <= a 0, Media, Desvío, Mínimo, 1er Cuartil, Mediana, 3er Cuartil, Máximo'.split(', ')\n",
    "    data = {k:v for k,v in zip(names, data)}\n",
    "    if show:\n",
    "        import matplotlib.pyplot as plt\n",
    "        import seaborn as sns\n",
    "        sns.set()\n",
    "        show = plt.figure()\n",
    "        sns.distplot(Q['Dif'], kde=False, norm_hist=True)\n",
    "        lim = max(np.abs([data['Max'], data['Min']])) + 0.1\n",
    "        plt.xlim(-lim, lim)  \n",
    "        if ylim: plt.ylim((0, ylim))\n",
    "        data = {t[0]: float(re.search(r\"[\\d\\-]+\\.*0*[.1-9]{0,2}\", str(t[1])).group(0)) for t in data.items()}\n",
    "\n",
    "    return data, show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(polish=False):\n",
    "    t0 = time()\n",
    "    print('Preparando optimización.')\n",
    "    A, q0, b, idx_ineqs = prepare_vars()\n",
    "    sol = solve_nras(A,q0.copy(),b,idx_ineqs)\n",
    "    Q = pd.read_csv(TMP_PATH+'Q1.csv', sep=';')\n",
    "    Q[neto_col + '_1'] = sol\n",
    "    Q['Dif'] = (1 - (Q[neto_col+'_1'] / Q[neto_col+'_w']))\n",
    "    Q.to_csv(TMP_PATH + 'Q1.csv', sep=';', index=False)\n",
    "    validar(Q=Q)\n",
    "    if polish:\n",
    "        sol, data = solve_ultra(A, sol, b, idx_ineqs, max_tries=2)\n",
    "        validar()\n",
    "    ctypes.windll.user32.MessageBoxW(0, f\"Distribución calculada. {time() - t0:.0f} segundos.\",  \"Terminado\", 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
